NLPfolder=/Users/lenin/OneDrive/jar/NLP/models/
inputSingleURL=http://www.yorkregion.com/news-story/4116596-health-hazards-at-daycare-where-girl-died/
isAppend=true
delimiter=!!!
crawlerType=type2Crawler
crawlerType#remarks={type1Crawler,type2Crawler,all};type1 uses jericho; type2 uses http
inputType=file
inputType#={"mongodburlandbody","file"}
outputType=writeCrawledText2OutFile
outputType#={"writeCrawledText2OutFile","mongodb","outNewUnCrawledURLFile"}
flag2=
flag2.remarks= You can do set of tagging of NLP such as location, date, person etc.
folder=/Users/lenin/Dropbox/#problems/p6/merged_used_for_INTELLIGENCE_course_7xxx/dummy.mergeall/ds10/crawling/
inputListOf_URLfileCSV=3rd_time_url_to_crawl_removedirtyRSSfeed.txt
inputListOf_URLfileCSV#remark=CrawledOutHTML1.txt!!!CrawledOutHTML.txt
fromLine=0
toLine=500000
URL_present_in_which_column_token=1
URL_present_in_which_column_token#remark=Starts from 1
outputFile=3rd_time_url_to_crawl_removedirtyRSSfeed_crawledBODYTEXT.txt
outdebugErrorAndURLfile=outdebugErrorAndURLfile.3rd_time_url_to_crawl_removedirtyRSSfeed1.txt
outAlreadyCrawledURLsINaFile=3rd_time_url_to_crawl_removedirtyRSSfeed_crawledBODYTEXT.txt
outdebugErrorAndURL=outdebugErrorAndURL.1_3rd_time_url_to_crawl_removedirtyRSSfeed.txt
outNewUnCrawledURLFile=outNewUnCrawledURLFile.1_3rd_time_url_to_crawl_removedirtyRSSfeed.txt
parseType=noparse
isSOPdebug=false
is_overwrite_flag_with_flag_model=true
is_overwrite_flag_with_flag_model.remark=if true, POSModel passed via param will be used.
in_Already_Crawled_File_URL_present_in_which_column_token=1
in_Already_Crawled_File_URL_present_in_which_column_token#remark=Starts from 1
method=readparsexmlfeeds